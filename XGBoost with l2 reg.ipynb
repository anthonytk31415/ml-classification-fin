{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9134572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preview:\n",
      "   age           job  marital  education default  balance housing loan  \\\n",
      "0   58    management  married   tertiary      no     2143     yes   no   \n",
      "1   44    technician   single  secondary      no       29     yes   no   \n",
      "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
      "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
      "4   33       unknown   single    unknown      no        1      no   no   \n",
      "\n",
      "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
      "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
      "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
      "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
      "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
      "4  unknown    5   may       198         1     -1         0  unknown  no  \n",
      "\n",
      "Dataset shape: (45211, 17)\n",
      "\n",
      "Categorical columns: ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
      "\n",
      "Numerical columns: ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
      "\n",
      "Feature names after one-hot encoding:\n",
      "0: age\n",
      "1: balance\n",
      "2: day\n",
      "3: duration\n",
      "4: campaign\n",
      "5: pdays\n",
      "6: previous\n",
      "7: job_blue-collar\n",
      "8: job_entrepreneur\n",
      "9: job_housemaid\n",
      "10: job_management\n",
      "11: job_retired\n",
      "12: job_self-employed\n",
      "13: job_services\n",
      "14: job_student\n",
      "15: job_technician\n",
      "16: job_unemployed\n",
      "17: job_unknown\n",
      "18: marital_married\n",
      "19: marital_single\n",
      "20: education_secondary\n",
      "21: education_tertiary\n",
      "22: education_unknown\n",
      "23: default_yes\n",
      "24: housing_yes\n",
      "25: loan_yes\n",
      "26: contact_telephone\n",
      "27: contact_unknown\n",
      "28: month_aug\n",
      "29: month_dec\n",
      "30: month_feb\n",
      "31: month_jan\n",
      "32: month_jul\n",
      "33: month_jun\n",
      "34: month_mar\n",
      "35: month_may\n",
      "36: month_nov\n",
      "37: month_oct\n",
      "38: month_sep\n",
      "39: poutcome_other\n",
      "40: poutcome_success\n",
      "41: poutcome_unknown\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# from get_dataset import X\n",
    "# from get_dataset import y\n",
    "\n",
    "# Step 1: Split the data into training and testing sets\n",
    "\n",
    "\n",
    "from get_dataset import X_train_tensor as X_train, X_test_tensor as X_test, y_train_tensor as y_train, y_test_tensor as y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4217908a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model with L2 regularization...\n",
      "XGBoost Model Accuracy: 0.9064\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.96      0.95      7952\n",
      "         1.0       0.65      0.48      0.55      1091\n",
      "\n",
      "    accuracy                           0.91      9043\n",
      "   macro avg       0.79      0.72      0.75      9043\n",
      "weighted avg       0.90      0.91      0.90      9043\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7673  279]\n",
      " [ 567  524]]\n",
      "\n",
      "XGBoost Final Test Accuracy: 0.9064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9064469755612076"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Step 2: Train XGBoost model with L2 (R2) regularization\n",
    "print(\"Training XGBoost model with L2 regularization...\")\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.2,\n",
    "    max_depth=4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=10,  # L2 Regularization\n",
    "    objective='binary:logistic',\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Make predictions and evaluate the model\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"XGBoost Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Step 4: PyTorch integration\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Training XGBoost with PyTorch DataLoader\n",
    "def train_xgb_with_pytorch_loader(train_loader):\n",
    "    all_X, all_y = [], []\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        all_X.append(X_batch.numpy())\n",
    "        all_y.append(y_batch.numpy())\n",
    "    \n",
    "    X_train_combined = np.vstack(all_X)\n",
    "    y_train_combined = np.concatenate(all_y)\n",
    "    \n",
    "    xgb_model_from_loader = xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=4,\n",
    "        reg_lambda=10,\n",
    "        objective='binary:logistic',\n",
    "        random_state=42\n",
    "    )\n",
    "    xgb_model_from_loader.fit(X_train_combined, y_train_combined)\n",
    "    return xgb_model_from_loader\n",
    "\n",
    "xgb_model_pytorch = train_xgb_with_pytorch_loader(train_loader)\n",
    "\n",
    "def evaluate_models(xgb_model, test_loader):\n",
    "    X_test_np = X_test\n",
    "    y_test_np = y_test\n",
    "    y_pred_xgb = xgb_model.predict(X_test_np)\n",
    "    xgb_accuracy = accuracy_score(y_test_np, y_pred_xgb)\n",
    "    print(f\"\\nXGBoost Final Test Accuracy: {xgb_accuracy:.4f}\")\n",
    "    return xgb_accuracy\n",
    "\n",
    "evaluate_models(xgb_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafa036b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
